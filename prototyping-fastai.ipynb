{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.basics           import *\n",
    "from fastai2.vision.all       import *\n",
    "from fastai2.medical.imaging  import *\n",
    "from fastai2.callback.tracker import *\n",
    "\n",
    "np.set_printoptions(linewidth=120)\n",
    "matplotlib.rcParams['image.cmap'] = 'bone'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we read in the metadata files (linked in the introduction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data')\n",
    "path_save = path/'saved_models'\n",
    "\n",
    "path_trn = path/'stage_1_train_images'\n",
    "path_tst = path/'stage_1_test_images'\n",
    "\n",
    "path_meta = path/'meta'/'meta'\n",
    "path_jpg = path/'train_jpg'/'train_jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb = pd.read_feather(path_meta/'comb.fth').set_index('SOPInstanceUID')\n",
    "df_tst  = pd.read_feather(path_meta/'df_tst.fth').set_index('SOPInstanceUID')\n",
    "df_samp = pd.read_feather(path_meta/'wgt_sample.fth').set_index('SOPInstanceUID')\n",
    "bins = (path_meta/'bins.pkl').load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train vs valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get better validation measures, we should split on patients, not just on studies, since that's how the test set is created.\n",
    "\n",
    "Here's a list of random patients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "patients = df_comb.PatientID.unique()\n",
    "pat_mask = np.random.random(len(patients))<0.8\n",
    "pat_trn = patients[pat_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#msss = MultilabelStratifiedShuffleSplit(n_splits=2, test_size=len(df_comb)//5, random_state=42)\n",
    "#X = df_comb.PatientID\n",
    "#Y = classes\n",
    "#\n",
    "## Get train and test index\n",
    "#msss_splits = next(msss.split(X, Y))\n",
    "#train_idx = msss_splits[0]\n",
    "#valid_idx = msss_splits[1]\n",
    "\n",
    "#len(train_idx), len(valid_idx), len(valid_idx)/len(train_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use that to take just the patients in a dataframe that match that mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    idx = L.range(df)\n",
    "    mask = df.PatientID.isin(pat_trn)\n",
    "    return idx[mask],idx[~mask]\n",
    "\n",
    "splits = split_data(df_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def split_data_stratified(df):\n",
    "#    idx = L.range(df)\n",
    "#    mask = df_samp.PatientID.isin(df_comb.iloc[train_idx].PatientID.values)\n",
    "#    return idx[mask],idx[~mask]\n",
    "#\n",
    "#splits = split_data_stratified(df_samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double-check that for a patient in the training set that their images are all in the first split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = df_samp.iloc[splits[0]]\n",
    "p1 = L.range(df_samp)[df_samp.PatientID==df_trn.PatientID[0]]\n",
    "assert len(p1) == len(set(p1) & set(splits[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare sample DataBunch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will grab our sample filenames for the initial pretraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename(o): return os.path.splitext(os.path.basename(o))[0]\n",
    "\n",
    "fns = L(list(df_samp.fname)).map(filename)\n",
    "fn = fns[0]\n",
    "fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a `DataBunch` that contains our sample data, so we need a function to convert a filename (pointing at a DICOM file) into a path to our sample JPEG files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn2image(fn): return PILCTScan.create((path_jpg/fn).with_suffix('.jpg'))\n",
    "fn2image(fn).show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to be able to grab the labels from this, which we can do by simply indexing into our sample `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htypes = ['any','epidural','intraparenchymal','intraventricular','subarachnoid','subdural']\n",
    "def fn2label(fn): return df_comb.loc[fn][htypes].values.astype(np.float32)\n",
    "fn2label(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a larger GPU or more workers, change batchsize and number-of-workers here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,nw = 128, 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use fastai's new [Transform Pipeline API](http://dev.fast.ai/pets.tutorial.html) to create the DataBunch, since this is extremely flexible, which is great for intermediate and advanced Kagglers. (Beginners will probably want to stick with the Data Blocks API). We create two transform pipelines, one to open the image file, and one to look up the label and create a tensor of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [[fn2image], [fn2label,EncodedMultiCategorize(htypes)]]\n",
    "\n",
    "dsrc = DataSource(fns, tfms, splits=splits)\n",
    "\n",
    "#nrm = Normalize(tensor([0.6]),tensor([0.25]))\n",
    "nrm = Normalize(tensor([0.1627, 0.1348, 0.1373]), tensor([0.2961, 0.2605, 0.1889]))\n",
    "\n",
    "aug = aug_transforms(max_lighting=0.1) #p_lighting=0.\n",
    "\n",
    "batch_tfms = [IntToFloatTensor(), nrm, Cuda(), *aug]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To support progressive resizing (one of the most useful tricks in the deep learning practitioner's toolbox!) we create a function that returns a dataset resized to a requested size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(bs, sz):\n",
    "    return dsrc.databunch(bs=bs, num_workers=nw, after_item=[ToTensor],\n",
    "                          after_batch=batch_tfms+[AffineCoordTfm(size=sz)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbch = get_data(128, 96)\n",
    "xb,yb = to_cpu(dbch.one_batch())\n",
    "dbch.show_batch(max_n=4, figsize=(9,6))\n",
    "xb.mean(),xb.std(),xb.shape,len(dbch.train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's track the accuracy of the *any* label as our main metric, since it's easy to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_any(inp, targ, thresh=0.5, sigmoid=True):\n",
    "    inp,targ = flatten_check(inp[:,0],targ[:,0])\n",
    "    if sigmoid: inp = inp.sigmoid()\n",
    "    return ((inp>thresh)==targ.bool()).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function in this competition is weighted, so let's train using that loss function too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(scale=1.0):\n",
    "    loss_weights = tensor(2.0, 1, 1, 1, 1, 1).cuda()*scale\n",
    "    return BaseLoss(nn.BCEWithLogitsLoss, pos_weight=loss_weights, floatify=True, flatten=False, \n",
    "        is_2d=False, activation=torch.sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll scale the loss initially to account for our sampling (since the original data had 14% rows with a positive label, and we resampled it to 50/50)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = get_loss(scale=1.0) #get_loss(0.14*2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_func = partial(Adam, wd=0.01, eps=1e-3)\n",
    "\n",
    "metrics=[accuracy_multi,accuracy_any]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to create our learner. We can use mixed precision (fp16) by simply adding a call to `to_fp16()`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner():\n",
    "    dbch = get_data(128,128)\n",
    "    learn = cnn_learner(dbch, xresnet50, loss_func=loss_func, opt_func=opt_func, metrics=metrics)\n",
    "    return learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model_dir = path_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leslie Smith's famous LR finder will give us a reasonable learning rate suggestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf = learn.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain on sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's our main routine for changing the size of the images in our DataBunch, doing one fine-tuning of the final layers, and then training the whole model for a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fit(bs,sz,epochs,lr, freeze=True, save_name='best'):\n",
    "    learn.dbunch = get_data(bs, sz)\n",
    "    if freeze:\n",
    "        if learn.opt is not None: learn.opt.clear_state()\n",
    "        learn.freeze()\n",
    "        learn.fit_one_cycle(1, slice(lr))\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(epochs, slice(lr), cbs=SaveModelCallback(fname=save_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pre-train at different sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can use `torch.cuda.empty_cache()` if anything goes wrong to reset the gpu memory allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## short training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do_fit(512, 96, 4, 1e-2, save_name='xresnet50_96px_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do_fit(192, 160, 3, 1e-3, save_name='xresnet50_96px_sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test with lightning augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(256, 96, 4, 1e-2, save_name='xresnet50_96px_sample_lightaugs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('xresnet50_96px_sample_lightaugs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(192, 160, 4, 2e-3, save_name='xresnet50_160px_sample_lightaugs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('xresnet50_160px_sample_lightaugs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(80, 256, 5, 2e-3, save_name='xresnet50_256px_sample_lightaugs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('xresnet50_256px_sample_lightaugs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best so far: \n",
    "1. new normalization, no lightning aug\n",
    "2. new normalization, 0.1 lightning aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test new normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(256, 96, 4, 1e-2, save_name='xresnet50_96px_sample_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('xresnet50_96px_sample_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(192, 160, 4, 2e-3, save_name='xresnet50_160px_sample_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('xresnet50_160px_sample_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(80, 256, 5, 2e-3, save_name='xresnet50_256px_sample_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('xresnet50_256px_sample_norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## long training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(256, 96, 4, 1e-2, save_name='xresnet50_96px_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('xresnet50_96px_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(192, 160, 4, 2e-3, save_name='xresnet50_160px_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('xresnet50_160px_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(80, 256, 5, 1e-3, save_name='xresnet50_256px_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('xresnet50_256px_sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit(80, 256, 5, 2e-4, save_name='xresnet50_256px_continued_sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale up to full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fine tune this model on the full dataset. We'll need all the filenames now, not just the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = L(list(df_comb.fname)).map(filename)\n",
    "splits = split_data(df_comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions are copied nearly verbatim from our [earlier cleanup notebook](https://www.kaggle.com/jhoward/cleaning-the-data-for-rapid-prototyping-fastai), so have a look there for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_pxrepr(dcm):\n",
    "    if dcm.PixelRepresentation != 0 or dcm.RescaleIntercept<-100: return\n",
    "    x = dcm.pixel_array + 1000\n",
    "    px_mode = 4096\n",
    "    x[x>=px_mode] = x[x>=px_mode] - px_mode\n",
    "    dcm.PixelData = x.tobytes()\n",
    "    dcm.RescaleIntercept = -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcm_tfm(fn): \n",
    "    fn = (path_trn/fn).with_suffix('.dcm')\n",
    "    try:\n",
    "        x = fn.dcmread()\n",
    "        fix_pxrepr(x)\n",
    "    except Exception as e:\n",
    "        print(fn,e)\n",
    "        raise SkipItemException\n",
    "    if x.Rows != 512 or x.Columns != 512: x.zoom_to((512,512))\n",
    "    px = x.scaled_px\n",
    "    return TensorImage(px.to_3chan(dicom_windows.brain,dicom_windows.subdural, bins=bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm = dcm_tfm(fns[0])\n",
    "show_images(dcm)\n",
    "dcm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some slight changes to our data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [[dcm_tfm], [fn2label,EncodedMultiCategorize(htypes)]]\n",
    "\n",
    "dsrc = DataSource(fns, tfms, splits=splits)\n",
    "\n",
    "nrm_full = Normalize(tensor([0.1627, 0.1348, 0.1373]), tensor([0.2961, 0.2605, 0.1889]))\n",
    "\n",
    "batch_tfms = [nrm_full, Cuda(), *aug]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(bs, sz):\n",
    "    return dsrc.databunch(bs=bs, num_workers=nw, after_batch=batch_tfms+[AffineCoordTfm(size=sz)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbch = get_data(128,96)\n",
    "x,y = to_cpu(dbch.one_batch())\n",
    "dbch.show_batch(max_n=4)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove the sample scaling from our loss function, since we're using the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = get_loss(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now fine-tune the final layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_tune(bs, sz, epochs, lr, save_name='best'):\n",
    "    dbch = get_data(bs, sz)\n",
    "    learn.dbunch = dbch\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(epochs, slice(lr), cbs=SaveModelCallback(fname=save_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## short training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit_tune(80, 256, 1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit_tune(64, 352, 1, 3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## long training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.opt.clear_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbch = get_data(48, 352)\n",
    "learn.dbunch = dbch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_tune(48, 352, 3, 1e-2, save_name='xresnet50_352px_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbch = get_data(20, 512)\n",
    "learn.dbunch = dbch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_tune(20, 512, 2, 1e-2, save_name='xresnet50_512px_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to submit. We can use the handy `test_dl` function to get an inference `DataLoader` ready, then we can check it looks OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fns = [(path_tst/f'{filename(o)}.dcm').absolute() for o in df_tst.fname.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbch = get_data(128,352)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = test_dl(dbch, test_fns)\n",
    "x = tst.one_batch()[0]\n",
    "x.min(),x.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass that to `get_preds` to get our predictions, and then clamp them just in case we have some extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,targs = learn.get_preds(dl=tst)\n",
    "preds_clipped = preds.clamp(.0001, .999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm too lazy to write a function that creates a submission file, so this code is stolen from Radek, with minor changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "labels = []\n",
    "\n",
    "for idx,pred in zip(df_tst.index, preds_clipped):\n",
    "    for i,label in enumerate(htypes):\n",
    "        ids.append(f\"{idx}_{label}\")\n",
    "        predicted_probability = '{0:1.10f}'.format(pred[i].item())\n",
    "        labels.append(predicted_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = pd.DataFrame({'ID': ids, 'Label': labels})\n",
    "df_csv.to_csv(f'submission.csv', index=False)\n",
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below if you want a link to download the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink, FileLinks\n",
    "# FileLink('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
